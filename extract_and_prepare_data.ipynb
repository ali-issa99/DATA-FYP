{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9P0Ki8kvMt05",
   "metadata": {
    "id": "9P0Ki8kvMt05"
   },
   "source": [
    "**split audio by detecting the sound**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd071b8",
   "metadata": {
    "id": "3bd071b8"
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr \n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "A=0\n",
    "def get_large_audio_transcription(path,silence=500):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_wav(path)  \n",
    "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
    "    \n",
    "    chunks = split_on_silence(\n",
    "    sound,\n",
    "\n",
    "    # split on silences longer than 1000ms (1 sec)\n",
    "    min_silence_len=600,\n",
    "\n",
    "    # anything under -16 dBFS is considered silence\n",
    "    silence_thresh = sound.dBFS-14,      \n",
    "\n",
    "    )\n",
    "\n",
    "    # now recombine the chunks so that the parts are at least 90 sec long\n",
    "    \n",
    "    folder_name = 'voices'\n",
    "        # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "            os.mkdir(folder_name)\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "#         A+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OcpAKkVZNHo5",
   "metadata": {
    "id": "OcpAKkVZNHo5"
   },
   "source": [
    "**load videos downloaded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81339b",
   "metadata": {
    "id": "0d81339b"
   },
   "outputs": [],
   "source": [
    "import wave\n",
    "import contextlib\n",
    "import os\n",
    "#hone enta lezim tnazil videos online, ykoune type .wav  w t7oton bi folder 2esmo videos\n",
    "directory='./videos/'\n",
    "voices=os.listdir(directory)\n",
    "\n",
    "for voice in voices:\n",
    "       get_large_audio_transcription(source+str(voice),silence=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cRUHu7XlNR-8",
   "metadata": {
    "id": "cRUHu7XlNR-8"
   },
   "source": [
    "Remove voices where duration is more than specific number of seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c6b27",
   "metadata": {
    "id": "1c1c6b27"
   },
   "outputs": [],
   "source": [
    "#calcul of duration and remove voice\n",
    "import wave\n",
    "import contextlib\n",
    "voices houwe lfolder li b2albo lvoices splitted\n",
    "source='./voices/'\n",
    "voices=os.listdir(source)\n",
    "\n",
    "\n",
    "for voice in voices:\n",
    "      with contextlib.closing(wave.open(source+str(voice),'r')) as f:\n",
    "            frames = f.getnframes()\n",
    "            rate = f.getframerate()\n",
    "            duration = frames / float(rate)\n",
    "            f.close()\n",
    "            if (duration<4 or duration >=9 ):    \n",
    "                  os.remove(source+str(voice))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tRuUIE3RNoQu",
   "metadata": {
    "id": "tRuUIE3RNoQu"
   },
   "source": [
    "**extract specific duration from an audio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c5dd6",
   "metadata": {
    "id": "963c5dd6"
   },
   "outputs": [],
   "source": [
    "def cut_voice(path_to_file,remove=True):\n",
    "    \n",
    "    # Import part 1 audio file\n",
    "    part_1 = AudioSegment.from_file(path_to_file)\n",
    "    # Remove the first four seconds of part 1\n",
    "    part_1_removed = part_1[:11000]\n",
    "    filename = os.path.join('./voice-trim', f\"{10}.wav\")\n",
    "    part_1_removed.export(filename, format=\"wav\")\n",
    "    os.remove(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uxrBIInwOSvs",
   "metadata": {
    "id": "uxrBIInwOSvs"
   },
   "source": [
    "**sorting the folder is necessary if the names of audio files are '1.wav', '2.wav', 3ashain 2eza enta mra2emon hek w keib transcript taba3on bel dor bi excel file, momken bas ta3melon load 7a yen3amalon sorting 8er.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2183e82",
   "metadata": {
    "id": "e2183e82"
   },
   "outputs": [],
   "source": [
    "# take second element for sort\n",
    "def sorting(elem):\n",
    "    return int(elem[:len(elem)-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H_aTsQYdObzT",
   "metadata": {
    "id": "H_aTsQYdObzT"
   },
   "source": [
    "Rename files in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0258582",
   "metadata": {
    "id": "c0258582"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path='./voices/'\n",
    "voices=os.listdir(path)\n",
    "voices.sort(key=sorting)\n",
    "\n",
    "\n",
    "for voice in voices :\n",
    "    old_name = path+str(voice)\n",
    "    os.rename(old_name,'./voices/'+str(L)+'.wav')\n",
    "    L+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-qvyXwtZOlS7",
   "metadata": {
    "id": "-qvyXwtZOlS7"
   },
   "source": [
    "**How to load model from hugging face**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633538f8",
   "metadata": {
    "id": "633538f8"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCTC, Wav2Vec2Processor\n",
    "\n",
    "model = AutoModelForCTC.from_pretrained('ali-issa/wav2vec2-Arabizi-gpu-colab-similar-to-german-param')\n",
    "processor = Wav2Vec2Processor.from_pretrained('ali-issa/wav2vec2-Arabizi-gpu-colab-similar-to-german-param')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f972d798",
   "metadata": {
    "id": "f972d798"
   },
   "outputs": [],
   "source": [
    "def predict(samples) :\n",
    "  inputs = processor(samples,return_tensors=\"pt\",sampling_rate=16000 ,padding=True)\n",
    "  logits = model(inputs.input_values).logits\n",
    "  pred_ids = torch.argmax(logits, dim=-1)[0]\n",
    "  predicted=processor.decode(pred_ids)\n",
    "  return predicted\n",
    "L=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hpyw7D96O6V-",
   "metadata": {
    "id": "hpyw7D96O6V-"
   },
   "source": [
    "1)sta5dim lmodel li 3melnelo load w fawit l voices ka input 3le w 7ot louput li houwe transcript b2aleb excel file\n",
    "\n",
    "2) Kamen na3melon load lal voices w nesta5dim API google kermel yotla3lna transcript men API google\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad6493c",
   "metadata": {
    "id": "6ad6493c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "import librosa\n",
    "import torch\n",
    "# Workbook is created\n",
    "wb = Workbook()\n",
    "# L hiye 3ibara 3an lrow li badna nektoub fiya lexcel file\n",
    "L=0\n",
    "\n",
    "# add_sheet is used to create sheet.\n",
    "sheet1 = wb.add_sheet('Sheet 1')\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "r = sr.Recognizer()\n",
    "directory='./voices/'\n",
    "voices=os.listdir(directory)\n",
    "voices.sort(key=sorting)\n",
    "\n",
    "# eza badna nesta5dim google api\n",
    "for voice in voices :\n",
    "    with sr.AudioFile(directory+str(voice)) as source:\n",
    "                    audio_data = r.record(source)\n",
    "                    text = r.recognize_google(audio_data,language='ar-LB')\n",
    "                    sheet1.write(L,0,text)\n",
    "                    print(L)\n",
    "                    L+=1  \n",
    "                    # save an excel file\n",
    "                    wb.save('transcript.xls')\n",
    "\n",
    "# eza badna nesta5dim l`model loaded from wav2vec \n",
    "for voice in voices :\n",
    "                    samples, sample_rate = librosa.load(directory+str(voice),sr=16000)\n",
    "                    # predict function li 5ala2neha fo2\n",
    "                    text=predict(samples)\n",
    "                    print(L)\n",
    "                    sheet1.write(L,0,text)\n",
    "                    L+=1   \n",
    "                    # save an excel file\n",
    "                    wb.save('transcript.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g3vLWhgySzE_",
   "metadata": {
    "id": "g3vLWhgySzE_"
   },
   "source": [
    " **Steps to Create the data set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZrqAzJTiS_j8",
   "metadata": {
    "id": "ZrqAzJTiS_j8"
   },
   "source": [
    "**1-load files as one dimensional array using librosa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db518c",
   "metadata": {
    "id": "e7db518c"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy\n",
    "samples=[]\n",
    "rate=[]\n",
    "directory='./voices/'\n",
    "voices=os.listdir(directory)\n",
    "voices.sort(key=sorting)\n",
    "\n",
    "for voice in voices :\n",
    "    sample,sr=librosa.load('./voices/'+str(voice[:]),sr=16000)\n",
    "    samples.append(sample)\n",
    "    rate.append(sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WvMgRM5OS7VV",
   "metadata": {
    "id": "WvMgRM5OS7VV"
   },
   "source": [
    "**2-read the corresoinding transcript of each voices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a306966",
   "metadata": {
    "id": "1a306966"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "file_loc = \"./transcript.xls\"\n",
    " \n",
    "sheet1=None\n",
    "with pd.ExcelFile(file_loc) as reader:\n",
    "    sheet1 = pd.read_excel(reader, sheet_name='Sheet 2')\n",
    "Text=[]\n",
    "for e in sheet1['Arabizi']:\n",
    "    Text.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eTyNXfr-Tb98",
   "metadata": {
    "id": "eTyNXfr-Tb98"
   },
   "source": [
    "**create train set,7atet 2000 3ashain dataset 7aliyan 2100, fa be5oud 2000 menon lal training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232942ae",
   "metadata": {
    "id": "232942ae"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame(\n",
    "   {\n",
    "       'audio':voices[:2000],\n",
    "       'samples':samples[:2000],\n",
    "       'sample_rate':rate[:2000],\n",
    "       'text':Text[:2000],\n",
    "   }\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LDE-C3lyVKGl",
   "metadata": {
    "id": "LDE-C3lyVKGl"
   },
   "source": [
    "**save l data bi path m3ayan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216d787",
   "metadata": {
    "id": "1216d787"
   },
   "outputs": [],
   "source": [
    "df.to_json(r'C:\\Users\\Ali\\Desktop\\FYP\\prepare_data_set\\arabizi_train_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jOpms-4hVWyV",
   "metadata": {
    "id": "jOpms-4hVWyV"
   },
   "source": [
    "**nafes l procedure for dev set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe9f2b8",
   "metadata": {
    "id": "bfe9f2b8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame(\n",
    "   {\n",
    "       'audio':voices[2000:],\n",
    "       'samples':samples[2000:],\n",
    "       'sample_rate':rate[2000:],\n",
    "       'text':Text[2000:],\n",
    "   }\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499e68e",
   "metadata": {
    "id": "9499e68e"
   },
   "outputs": [],
   "source": [
    "df.to_json(r'C:\\Users\\Ali\\Desktop\\FYP\\prepare_data_set\\arabizi_test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5EzGKQu_ViCW",
   "metadata": {
    "id": "5EzGKQu_ViCW"
   },
   "source": [
    "**ne7soub 3adad se3at lmawjoud bel folder li b2albo l voices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecbee4d",
   "metadata": {
    "id": "fecbee4d"
   },
   "outputs": [],
   "source": [
    "#calcul of duration and remove voice\n",
    "import wave\n",
    "import contextlib\n",
    "import os\n",
    "source='./part-1/'\n",
    "voices=os.listdir(source)\n",
    "voices.sort(key=sorting)\n",
    "liste=[]\n",
    "\n",
    "for voice in voices:\n",
    "      with contextlib.closing(wave.open(source+str(voice),'r')) as f:\n",
    "            frames = f.getnframes()\n",
    "            rate = f.getframerate()\n",
    "            duration = frames / float(rate)\n",
    "            liste.append(duration)\n",
    "            f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c7e66",
   "metadata": {
    "id": "3b7c7e66"
   },
   "outputs": [],
   "source": [
    "x=0\n",
    "for elem in liste:\n",
    "    x+=elem\n",
    "# printing total value\n",
    "print(\"number of hours: \", x/3600)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "extract_and_prepare_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
